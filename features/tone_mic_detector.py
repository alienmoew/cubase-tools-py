"""
Tone Mic Detector - ƒêi·ªÅu ch·ªânh bass (LOW) v√† treble (HIGH) c·ªßa mic
"""
import time
import pyautogui
import cv2
import numpy as np

import config
from features.base_feature import BaseFeature
from utils.helpers import ImageHelper, TemplateHelper, MessageHelper, MouseHelper, OCRHelper
from utils.process_finder import CubaseProcessFinder
from utils.window_manager import WindowManager


class ToneMicDetector(BaseFeature):
    """T√≠nh nƒÉng ƒëi·ªÅu ch·ªânh tone mic (bass/treble) tr·ª±c ti·∫øp trong Cubase."""
    
    def __init__(self):
        super().__init__()
        
        # Template path
        self.template_path = config.TEMPLATE_PATHS['tone_mic_template']
        
        # Kh·ªüi t·∫°o OCR
        OCRHelper.setup_tesseract()
        
    def get_name(self):
        """Tr·∫£ v·ªÅ t√™n hi·ªÉn th·ªã c·ªßa detector."""
        return "Tone Mic"
    
    def _find_cubase_process(self):
        """T√¨m ti·∫øn tr√¨nh Cubase."""
        proc = CubaseProcessFinder.find()
        if not proc:
            print("‚ùå Kh√¥ng t√¨m th·∫•y ti·∫øn tr√¨nh Cubase!")
            MessageHelper.show_error(
                "L·ªói Cubase", 
                "Kh√¥ng t√¨m th·∫•y ti·∫øn tr√¨nh Cubase ƒëang ch·∫°y!\n\nVui l√≤ng m·ªü Cubase tr∆∞·ªõc khi s·ª≠ d·ª•ng ch·ª©c nƒÉng n√†y."
            )
        return proc

    def _focus_cubase_window(self, proc):
        """Focus c·ª≠a s·ªï Cubase."""
        try:
            hwnd = WindowManager.focus_window_by_pid(proc.info["pid"])
        except Exception as e:
            print(f"‚ùå L·ªói khi focus Cubase window: {e}")
            MessageHelper.show_error(
                "L·ªói Focus Window", 
                "Kh√¥ng th·ªÉ focus c·ª≠a s·ªï Cubase!"
            )
            return None
        
        time.sleep(0.3)
        return hwnd
        
    def _find_xvox_window(self):
        """T√¨m c·ª≠a s·ªï XVox plugin."""
        # Try different possible window titles for XVox
        possible_titles = ["Xvox", "XVOX", "xvox", "X-Vox", "X_Vox"]
        
        for title in possible_titles:
            plugin_win = WindowManager.find_window(title)
            if plugin_win:
                print(f"‚úÖ Found XVox window: {title}")
                plugin_win.activate()
                time.sleep(0.3)
                return plugin_win
        
        print("‚ùå XVox plugin window not found")
        MessageHelper.show_error(
            "L·ªói XVox Plugin", 
            "Kh√¥ng t√¨m th·∫•y XVox plugin window!\n\nVui l√≤ng:\n‚Ä¢ M·ªü XVox plugin trong Cubase\n‚Ä¢ ƒê·∫£m b·∫£o c·ª≠a s·ªï plugin hi·ªÉn th·ªã tr√™n m√†n h√¨nh"
        )
        return None
    
    def _find_tone_mic_template(self, xvox_window):
        """T√¨m tone mic template v√† OCR v√πng ƒë√≥ ƒë·ªÉ t√¨m LOW/HIGH trong XVox plugin."""
        try:
            # L·∫•y th√¥ng tin c·ª≠a s·ªï XVox
            x, y, w, h = xvox_window.left, xvox_window.top, xvox_window.width, xvox_window.height
            print(f"üìê XVox window: {x}, {y}, {w}x{h}")
            
            # Screenshot XVox window
            screenshot = pyautogui.screenshot(region=(x, y, w, h))
            screenshot_np = np.array(screenshot)
            screenshot_gray = cv2.cvtColor(screenshot_np, cv2.COLOR_RGB2GRAY)
            
            print(f"üìê XVox screenshot size: {w}x{h}")
            
            # Load template
            template = cv2.imread(self.template_path, cv2.IMREAD_GRAYSCALE)
            if template is None:
                print(f"‚ùå Cannot load tone mic template: {self.template_path}")
                return None
                
            template_h, template_w = template.shape[:2]
            print(f"üìê Tone Mic template size: {template_w}x{template_h}")
            
            # Adaptive template matching
            best_result = TemplateHelper.adaptive_template_match(screenshot_gray, template)
            
            print(f"üèÜ Tone Mic best method: {best_result['method']}")
            print(f"üîç Tone Mic confidence: {best_result['confidence']:.3f}")
            print(f"üìè Tone Mic scale: {best_result['scale']:.2f}")
            
            if best_result['confidence'] < config.TEMPLATE_MATCH_THRESHOLD:
                print(f"‚ùå Tone Mic template confidence too low: {best_result['confidence']:.3f}")
                return None
            
            # Template match coordinates
            match_x, match_y = best_result['location']
            scaled_w, scaled_h = best_result['template_size']
            
            print(f"‚úÖ Tone Mic template found at: ({match_x}, {match_y}) with size {scaled_w}x{scaled_h}")
            
            # Define OCR region (to√†n b·ªô template area)
            ocr_x, ocr_y = match_x, match_y
            ocr_w, ocr_h = scaled_w, scaled_h
            
            print(f"üìñ OCR region: ({ocr_x}, {ocr_y}, {ocr_w}x{ocr_h})")
            print(f"üîç OCR region size: {ocr_w}x{ocr_h}")
            
            # Direct capture OCR region ƒë·ªÉ tr√°nh double crop color shift
            absolute_ocr_x = x + ocr_x
            absolute_ocr_y = y + ocr_y
            ocr_region_pil = pyautogui.screenshot(region=(absolute_ocr_x, absolute_ocr_y, ocr_w, ocr_h))
            
            # Convert OCR region to grayscale nh∆∞ Auto-Tune detector
            print("üìñ Converting OCR region to grayscale...")
            ocr_region_np = np.array(ocr_region_pil)
            ocr_region_gray = cv2.cvtColor(ocr_region_np, cv2.COLOR_RGB2GRAY)
            
            # Convert back to PIL for OCR
            from PIL import Image
            ocr_region_gray_pil = Image.fromarray(ocr_region_gray, mode='L')
            
            print("üìñ OCR on grayscale region...")
            ocr_data = OCRHelper.extract_text_data(ocr_region_gray_pil)
            words = OCRHelper.get_text_words(ocr_data)
            print(f"üìú OCR text in tone mic region: {words}")
            
            # T√¨m v·ªã tr√≠ LOW v√† HIGH
            low_pos = None
            high_pos = None
            
            for i, text in enumerate(ocr_data["text"]):
                if text and text.strip():
                    text_clean = text.strip().upper()
                    
                    if "LOW" in text_clean:
                        # T√≠nh v·ªã tr√≠ absolute c·ªßa LOW
                        low_x = x + ocr_x + ocr_data["left"][i] + ocr_data["width"][i] // 2
                        low_y = y + ocr_y + ocr_data["top"][i] + ocr_data["height"][i] // 2
                        low_pos = (low_x, low_y)
                        print(f"üîâ Found LOW at: ({low_x}, {low_y})")
                    
                    elif "HIGH" in text_clean:
                        # T√≠nh v·ªã tr√≠ absolute c·ªßa HIGH
                        high_x = x + ocr_x + ocr_data["left"][i] + ocr_data["width"][i] // 2
                        high_y = y + ocr_y + ocr_data["top"][i] + ocr_data["height"][i] // 2
                        high_pos = (high_x, high_y)
                        print(f"üîä Found HIGH at: ({high_x}, {high_y})")
            
            # Fallback logic: N·∫øu kh√¥ng detect ƒë∆∞·ª£c LOW/HIGH, d√πng position-based approach
            if not low_pos or not high_pos:
                print("‚ö†Ô∏è OCR kh√¥ng detect ƒë·ªß LOW/HIGH, s·ª≠ d·ª•ng position-based fallback...")
                
                # L·ªçc ra c√°c text c√≥ content
                valid_texts = []
                for i, text in enumerate(ocr_data["text"]):
                    if text and text.strip():
                        text_info = {
                            'text': text.strip(),
                            'index': i,
                            'left': ocr_data["left"][i],
                            'top': ocr_data["top"][i],
                            'width': ocr_data["width"][i],
                            'height': ocr_data["height"][i]
                        }
                        valid_texts.append(text_info)
                
                print(f"üìù Valid OCR texts: {[t['text'] for t in valid_texts]}")
                
                # N·∫øu c√≥ √≠t nh·∫•t 3 elements (ƒë·ªÉ c√≥ index 0 v√† 2)
                if len(valid_texts) >= 3:
                    # Element ƒë·∫ßu ti√™n (index 0) = LOW
                    if not low_pos:
                        low_info = valid_texts[0]
                        low_x = x + ocr_x + low_info['left'] + low_info['width'] // 2
                        low_y = y + ocr_y + low_info['top'] + low_info['height'] // 2
                        low_pos = (low_x, low_y)
                        print(f"üîâ Fallback LOW ('{low_info['text']}') at: ({low_x}, {low_y})")
                    
                    # Element th·ª© 3 (index 2) = HIGH  
                    if not high_pos:
                        high_info = valid_texts[2]
                        high_x = x + ocr_x + high_info['left'] + high_info['width'] // 2
                        high_y = y + ocr_y + high_info['top'] + high_info['height'] // 2
                        high_pos = (high_x, high_y)
                        print(f"üîä Fallback HIGH ('{high_info['text']}') at: ({high_x}, {high_y})")
                
                else:
                    print(f"‚ùå Kh√¥ng ƒë·ªß OCR elements ƒë·ªÉ fallback (c·∫ßn √≠t nh·∫•t 3, c√≥ {len(valid_texts)})")
            
            # Save debug image
            debug_filename = "tone_mic_ocr_debug.png"
            
            # T·∫°o debug image v·ªõi template match v√† OCR results
            debug_image = screenshot_np.copy()
            
            # V·∫Ω template match box
            cv2.rectangle(debug_image, 
                        (match_x, match_y), 
                        (match_x + scaled_w, match_y + scaled_h), 
                        (0, 255, 0), 2)
            cv2.putText(debug_image, f"Template Match {best_result['confidence']:.3f}", 
                       (match_x, match_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # V·∫Ω OCR region box
            cv2.rectangle(debug_image, 
                        (ocr_x, ocr_y), 
                        (ocr_x + ocr_w, ocr_y + ocr_h), 
                        (255, 0, 0), 2)
            cv2.putText(debug_image, "OCR Region", 
                       (ocr_x, ocr_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
            
            # V·∫Ω LOW v√† HIGH positions
            if low_pos:
                rel_low_x = low_pos[0] - x
                rel_low_y = low_pos[1] - y
                cv2.circle(debug_image, (rel_low_x, rel_low_y), 5, (0, 0, 255), -1)
                cv2.putText(debug_image, "LOW", (rel_low_x + 10, rel_low_y), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
            
            if high_pos:
                rel_high_x = high_pos[0] - x
                rel_high_y = high_pos[1] - y
                cv2.circle(debug_image, (rel_high_x, rel_high_y), 5, (255, 0, 255), -1)
                cv2.putText(debug_image, "HIGH", (rel_high_x + 10, rel_high_y), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)
            
            # Save debug image
            debug_path = f"result/{debug_filename}"
            cv2.imwrite(debug_path, debug_image)
            print(f"üñº Tone Mic OCR debug saved -> {debug_path}")
            
            return {
                'low_pos': low_pos,
                'high_pos': high_pos,
                'template_match': best_result,
                'ocr_words': words
            }
            
        except Exception as e:
            print(f"‚ùå Error in tone mic template detection: {e}")
            return None
    
    def detect_tone_mic_controls(self):
        """Ph√°t hi·ªán c√°c control c·ªßa tone mic v√† t·∫°o debug image."""
        print("üé§ Tone Mic Detector - Detecting controls in XVox...")
        
        # 1. Find v√† focus Cubase process
        proc = self._find_cubase_process()
        if not proc:
            return False
        
        # 2. Focus Cubase window
        if not self._focus_cubase_window(proc):
            return False
        
        # 3. Find XVox plugin window
        xvox_window = self._find_xvox_window()
        if not xvox_window:
            return False
        
        # 4. Find tone mic template v√† OCR trong XVox
        result = self._find_tone_mic_template(xvox_window)
        if not result:
            print("‚ùå Failed to detect tone mic controls")
            return False
        
        # 4. Report results
        low_pos = result['low_pos']
        high_pos = result['high_pos']
        
        if low_pos and high_pos:
            print(f"‚úÖ Successfully detected both controls:")
            print(f"   üîâ LOW (Bass): {low_pos}")
            print(f"   üîä HIGH (Treble): {high_pos}")
            return True
        elif low_pos:
            print(f"‚ö†Ô∏è Only detected LOW (Bass): {low_pos}")
            return True
        elif high_pos:
            print(f"‚ö†Ô∏è Only detected HIGH (Treble): {high_pos}")
            return True
        else:
            print("‚ùå Could not detect LOW or HIGH controls")
            return False
    
    def set_bass_value(self, value):
        """
        Set bass (LOW) value v·ªõi workflow: OCR -> click text -> click 40% -> triple-click + Ctrl+A -> type value
        Range: -30 to 30
        """
        # Validate range
        if value < -30:
            value = -30
            print(f"‚ö†Ô∏è Bass value clamped to minimum: {value}")
        elif value > 30:
            value = 30
            print(f"‚ö†Ô∏è Bass value clamped to maximum: {value}")
            
        print(f"üîâ Setting Bass (LOW) value to: {value}")
        
        # Store original cursor position
        original_pos = pyautogui.position()
        
        try:
            # 1. Find v√† focus Cubase process
            proc = self._find_cubase_process()
            if not proc:
                return False
            
            # 2. Focus Cubase window
            if not self._focus_cubase_window(proc):
                return False
            
            # 3. Find XVox plugin window
            xvox_window = self._find_xvox_window()
            if not xvox_window:
                return False
            
            # 4. Find tone mic template v√† OCR ƒë·ªÉ t√¨m LOW text
            result = self._find_tone_mic_template(xvox_window)
            if not result or not result.get('low_pos'):
                print("‚ùå Could not find LOW text position")
                return False
            
            low_pos = result['low_pos']
            print(f"‚úÖ Found LOW text at: {low_pos}")
            
            # 5. Click v√†o LOW text
            pyautogui.click(low_pos[0], low_pos[1])
            time.sleep(0.2)
            print(f"üñ± Clicked on LOW text at {low_pos}")
            
            # 6. Click ·ªü v·ªã tr√≠ chi·ªÅu d·ªçc 40% t·ª´ tr√™n xu·ªëng (gi·ªØ nguy√™n x coordinate)
            # T√≠nh to√°n v·ªã tr√≠ 40% theo chi·ªÅu d·ªçc t·ª´ top c·ªßa template
            template_match = result['template_match']
            template_top = template_match['location'][1]
            template_height = template_match['template_size'][1]  # template_size is (w, h)
            
            click_y = template_top + (template_height * 0.40)
            click_x = low_pos[0]  # Gi·ªØ nguy√™n x coordinate c·ªßa LOW text
            
            pyautogui.click(click_x, click_y)
            time.sleep(0.2)
            print(f"üñ± Clicked at 40% position: ({click_x}, {click_y})")
            
            # 7. Multiple selection methods ƒë·ªÉ ensure text ƒë∆∞·ª£c select
            pyautogui.tripleClick(click_x, click_y)
            time.sleep(0.1)
            print("üñ± Triple-clicked to select text")
            
            # Th·ª≠ th√™m Ctrl+A ƒë·ªÉ ch·∫Øc ch·∫Øn
            pyautogui.hotkey('ctrl', 'a')
            time.sleep(0.1)
            print("‚å®Ô∏è Also tried Ctrl+A")
            
            # 8. Type gi√° tr·ªã m·ªõi (s·∫Ω replace selected text)
            pyautogui.typewrite(str(value))
            time.sleep(0.1)
            print(f"‚å®Ô∏è Typed value: {value}")
            
            # 9. Nh·∫•n Enter ƒë·ªÉ confirm
            pyautogui.press('enter')
            time.sleep(0.2)
            print("‚å®Ô∏è Pressed Enter to confirm")
            
            print(f"‚úÖ Successfully set Bass (LOW) to {value}")
            return True
            
        except Exception as e:
            print(f"‚ùå Error setting bass value: {e}")
            return False
        finally:
            # Restore cursor position at the end of entire workflow
            pyautogui.moveTo(original_pos[0], original_pos[1])
    
    def set_treble_value(self, value):
        """
        Set treble (HIGH) value v·ªõi workflow: OCR -> click text -> click 40% -> triple-click + Ctrl+A -> type value
        Range: -20 to 30
        """
        # Validate range
        if value < -20:
            value = -20
            print(f"‚ö†Ô∏è Treble value clamped to minimum: {value}")
        elif value > 30:
            value = 30
            print(f"‚ö†Ô∏è Treble value clamped to maximum: {value}")
            
        print(f"üîä Setting Treble (HIGH) value to: {value}")
        
        # Store original cursor position
        original_pos = pyautogui.position()
        
        try:
            # 1. Find v√† focus Cubase process
            proc = self._find_cubase_process()
            if not proc:
                return False
            
            # 2. Focus Cubase window
            if not self._focus_cubase_window(proc):
                return False
            
            # 3. Find XVox plugin window
            xvox_window = self._find_xvox_window()
            if not xvox_window:
                return False
            
            # 4. Find tone mic template v√† OCR ƒë·ªÉ t√¨m HIGH text
            result = self._find_tone_mic_template(xvox_window)
            if not result or not result.get('high_pos'):
                print("‚ùå Could not find HIGH text position")
                return False
            
            high_pos = result['high_pos']
            print(f"‚úÖ Found HIGH text at: {high_pos}")
            
            # 5. Click v√†o HIGH text
            pyautogui.click(high_pos[0], high_pos[1])
            time.sleep(0.2)
            print(f"üñ± Clicked on HIGH text at {high_pos}")
            
            # 6. Click ·ªü v·ªã tr√≠ chi·ªÅu d·ªçc 40% t·ª´ tr√™n xu·ªëng (gi·ªØ nguy√™n x coordinate)
            # T√≠nh to√°n v·ªã tr√≠ 40% theo chi·ªÅu d·ªçc t·ª´ top c·ªßa template
            template_match = result['template_match']
            template_top = template_match['location'][1]
            template_height = template_match['template_size'][1]  # template_size is (w, h)
            
            click_y = template_top + (template_height * 0.40)
            click_x = high_pos[0]  # Gi·ªØ nguy√™n x coordinate c·ªßa HIGH text
            
            pyautogui.click(click_x, click_y)
            time.sleep(0.2)
            print(f"üñ± Clicked at 40% position: ({click_x}, {click_y})")
            
            # 7. Multiple selection methods ƒë·ªÉ ensure text ƒë∆∞·ª£c select
            pyautogui.tripleClick(click_x, click_y)
            time.sleep(0.1)
            print("üñ± Triple-clicked to select text")
            
            # Th·ª≠ th√™m Ctrl+A ƒë·ªÉ ch·∫Øc ch·∫Øn
            pyautogui.hotkey('ctrl', 'a')
            time.sleep(0.1)
            print("‚å®Ô∏è Also tried Ctrl+A")
            
            # 8. Type gi√° tr·ªã m·ªõi (s·∫Ω replace selected text)
            pyautogui.typewrite(str(value))
            time.sleep(0.1)
            print(f"‚å®Ô∏è Typed value: {value}")
            
            # 9. Nh·∫•n Enter ƒë·ªÉ confirm
            pyautogui.press('enter')
            time.sleep(0.2)
            print("‚å®Ô∏è Pressed Enter to confirm")
            
            print(f"‚úÖ Successfully set Treble (HIGH) to {value}")
            return True
            
        except Exception as e:
            print(f"‚ùå Error setting treble value: {e}")
            return False
        finally:
            # Restore cursor position at the end of entire workflow
            pyautogui.moveTo(original_pos[0], original_pos[1])
    
    def execute(self):
        """Execute tone mic detection."""
        return self.detect_tone_mic_controls()