"""
XVox Detector - ƒêi·ªÅu ch·ªânh t·∫•t c·∫£ controls c·ªßa plugin XVox
Bao g·ªìm: COMP, Reverb, Bass (LOW), Treble (HIGH)
"""
import time
import pyautogui
import cv2
import numpy as np

import config
from features.base_feature import BaseFeature
from utils.helpers import ImageHelper, TemplateHelper, MessageHelper, MouseHelper, OCRHelper, ConfigHelper

class XVoxDetector(BaseFeature):
    """T√≠nh nƒÉng ƒëi·ªÅu ch·ªânh t·∫•t c·∫£ controls c·ªßa XVox plugin."""
    
    def __init__(self):
        super().__init__()
        self.feature_name = "XVox Controls"
        
        # Setup Tesseract for OCR (like original)
        OCRHelper.setup_tesseract()
        
        # Template paths
        self.comp_template_path = config.TEMPLATE_PATHS['comp_template']
        self.reverb_template_path = config.TEMPLATE_PATHS['reverb_template'] 
        self.tone_mic_template_path = config.TEMPLATE_PATHS['tone_mic_template']
        
        # Load default values
        self.default_values = ConfigHelper.load_default_values()
        
        # COMP settings
        self.comp_min = self.default_values.get('xvox_volume_min', 30)
        self.comp_max = self.default_values.get('xvox_volume_max', 60)
        self.comp_default = self.default_values.get('xvox_volume_default', 45)
        self.current_comp = self.comp_default
        
        # Reverb settings
        self.reverb_min = self.default_values.get('reverb_min', 30)
        self.reverb_max = self.default_values.get('reverb_max', 42)
        self.reverb_default = self.default_values.get('reverb_default', 36)
        self.current_reverb = self.reverb_default
        
        # Bass settings
        self.bass_min = self.default_values.get('bass_min', -30)
        self.bass_max = self.default_values.get('bass_max', 30)
        self.bass_default = self.default_values.get('bass_default', 0)
        self.current_bass = self.bass_default
        
        # Treble settings  
        self.treble_min = self.default_values.get('treble_min', -20)
        self.treble_max = self.default_values.get('treble_max', 30)
        self.treble_default = self.default_values.get('treble_default', 0)
        self.current_treble = self.treble_default
        
    def get_name(self):
        """Tr·∫£ v·ªÅ t√™n hi·ªÉn th·ªã c·ªßa detector."""
        return "XVox Controls"
    
    def _find_cubase_process(self):
        """T√¨m Cubase process."""
        from utils.process_finder import CubaseProcessFinder
        proc = CubaseProcessFinder.find()
        if not proc:
            print("‚ùå Cubase process not found!")
            MessageHelper.show_error("L·ªói Process", "Kh√¥ng t√¨m th·∫•y Cubase process!")
        return proc
    
    def _find_xvox_window(self):
        """T√¨m c·ª≠a s·ªï XVox plugin."""
        from utils.window_manager import WindowManager
        import pygetwindow as gw
        
        # Try different possible window titles for XVox
        possible_titles = ["Xvox", "XVOX", "xvox", "X-Vox", "X_Vox", "XVox", "X Vox"]
        
        for title in possible_titles:
            plugin_win = WindowManager.find_window(title)
            if plugin_win:
                print(f"‚úÖ Found XVox window: {title}")
                return plugin_win
        
        # Debug: Print all available windows
        print("‚ùå XVox plugin window not found")
        print("üí° Searching for windows containing 'vox' or 'x-vox'...")
        all_windows = gw.getAllWindows()
        vox_windows = [w for w in all_windows if 'vox' in w.title.lower()]
        
        if vox_windows:
            print(f"üìã Found {len(vox_windows)} window(s) with 'vox' in title:")
            for w in vox_windows:
                print(f"   ‚Ä¢ '{w.title}'")
        else:
            print("üí° No windows with 'vox' in title found")
        
        print("üí° Make sure XVox plugin is open and visible")
        return None
    
    def _focus_cubase_window(self, proc):
        """Focus c·ª≠a s·ªï Cubase."""
        from utils.window_manager import WindowManager
        
        hwnd = WindowManager.focus_window_by_pid(proc.info["pid"])
        if not hwnd:
            print("‚ùå Kh√¥ng th·ªÉ focus c·ª≠a s·ªï Cubase!")
            MessageHelper.show_error("L·ªói Focus Window", "Kh√¥ng th·ªÉ focus c·ª≠a s·ªï Cubase!")
            return None
        
        time.sleep(0.1)  # Gi·∫£m t·ª´ 0.3 xu·ªëng 0.1
        return hwnd
    
    def _find_template_match(self, plugin_win, template_path, control_name):
        """T√¨m template match cho control c·ª• th·ªÉ."""
        # Ch·ª• ·∫£nh m√†n h√¨nh v√πng plugin
        x, y, w, h = plugin_win.left, plugin_win.top, plugin_win.width, plugin_win.height
        screenshot = pyautogui.screenshot(region=(x, y, w, h))
        screenshot_np = np.array(screenshot)
        screenshot_gray = cv2.cvtColor(screenshot_np, cv2.COLOR_RGB2GRAY)

        print(f"üìê XVox plugin window size: {w}x{h}")

        # Load template
        template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)
        if template is None:
            print(f"‚ùå Kh√¥ng th·ªÉ load template: {template_path}")
            return None, 0

        template_h, template_w = template.shape[:2]
        print(f"üìê {control_name} template size: {template_w}x{template_h}")

        # Adaptive template matching
        best_result = TemplateHelper.adaptive_template_match(screenshot_gray, template)
        
        print(f"üèÜ {control_name} best method: {best_result['method']}")
        print(f"üîç {control_name} confidence: {best_result['confidence']:.3f}")
        print(f"üìè {control_name} scale: {best_result['scale']:.2f}")

        # Save debug image
        debug_filename = f"{control_name.lower()}_adaptive_debug.png"
        
        if best_result['scale'] != 1.0:
            scaled_w, scaled_h = best_result['template_size']
            debug_template = cv2.resize(template, (scaled_w, scaled_h))
        else:
            debug_template = template
        
        debug_path = ImageHelper.save_template_debug_image(
            screenshot_np, debug_template, best_result['location'], 
            best_result['confidence'], debug_filename
        )
        print(f"üñº {control_name} debug saved -> {debug_path}")

        if best_result['confidence'] < config.TEMPLATE_MATCH_THRESHOLD:
            print(f"‚ùå {control_name} template not found. Confidence: {best_result['confidence']:.3f}")
            return None, best_result['confidence']

        # T√≠nh to√°n v·ªã tr√≠ click
        scaled_w, scaled_h = best_result['template_size']
        click_x = x + best_result['location'][0] + scaled_w // 2
        click_y = y + best_result['location'][1] + scaled_h // 2

        print(f"‚úÖ {control_name} template found with confidence: {best_result['confidence']:.3f}")
        print(f"üéØ {control_name} click position: ({click_x}, {click_y}) [Scale: {best_result['scale']:.2f}]")

        return {'click_pos': (click_x, click_y), 'template_match': best_result}, best_result['confidence']
    
    # ==================== COMP METHODS ====================
    
    def set_comp_value(self, value):
        """ƒê·∫∑t gi√° tr·ªã COMP."""
        value = max(self.comp_min, min(self.comp_max, int(value)))
        
        print(f"üéõÔ∏è XVox COMP - Setting value to: {value}")
        
        # Store original cursor position
        original_pos = pyautogui.position()
        
        try:
            # 1. Find v√† focus Cubase process
            proc = self._find_cubase_process()
            if not proc:
                return False
                
            # 2. Focus Cubase window
            if not self._focus_cubase_window(proc):
                return False
            
            # 3. Find XVox plugin window
            plugin_win = self._find_xvox_window()
            if not plugin_win:
                return False
            
            # 4. Focus plugin window
            plugin_win.activate()
            time.sleep(0.1)  # Gi·∫£m t·ª´ 0.3 xu·ªëng 0.1
            
            # 5. Find COMP template match
            match_result = self._find_template_match(plugin_win, self.comp_template_path, "COMP")
            if not match_result or match_result[0] is None:
                return False
            
            result_data, confidence = match_result
            click_x, click_y = result_data['click_pos']
            
            # 6. Perform COMP action
            print(f"üëÜ Clicking COMP center: ({click_x}, {click_y})")
            pyautogui.click(click_x, click_y)
            time.sleep(0.05)  # Gi·∫£m t·ª´ 0.1 xu·ªëng 0.05
            
            print("‚è∞ Waiting 0.2s...")  # Gi·∫£m t·ª´ 0.5s xu·ªëng 0.2s
            time.sleep(0.2)
            
            # Click above template for input field
            estimated_template_height = 100
            template_top_y = click_y - (estimated_template_height // 2)
            top_click_y = template_top_y - 15
            print(f"üëÜ Double clicking above template: ({click_x}, {top_click_y})")
            pyautogui.doubleClick(click_x, top_click_y)
            time.sleep(0.1)  # Gi·∫£m t·ª´ 0.2 xu·ªëng 0.1
            
            print(f"‚å®Ô∏è Typing COMP value: {value}")
            pyautogui.typewrite(str(value))
            time.sleep(0.05)  # Gi·∫£m t·ª´ 0.1 xu·ªëng 0.05
            
            print("‚Ü©Ô∏è Pressing Enter")
            pyautogui.press('enter')
            time.sleep(0.1)  # Gi·∫£m t·ª´ 0.2 xu·ªëng 0.1
            
            print(f"‚úÖ COMP set to {value} successfully")
            self.current_comp = value
            return True
            
        except Exception as e:
            print(f"‚ùå Error setting COMP value: {e}")
            return False
        finally:
            # Restore cursor position
            pyautogui.moveTo(original_pos[0], original_pos[1])
    
    # ==================== REVERB METHODS ====================
    
    def set_reverb_value(self, value):
        """ƒê·∫∑t gi√° tr·ªã Reverb."""
        value = max(self.reverb_min, min(self.reverb_max, int(value)))
        
        print(f"üåä XVox Reverb - Setting value to: {value}")
        
        # Store original cursor position
        original_pos = pyautogui.position()
        
        try:
            # 1-4. Same setup as COMP
            proc = self._find_cubase_process()
            if not proc:
                return False
                
            if not self._focus_cubase_window(proc):
                return False
            
            plugin_win = self._find_xvox_window()
            if not plugin_win:
                return False
            
            plugin_win.activate()
            time.sleep(0.1)  # Gi·∫£m t·ª´ 0.3 xu·ªëng 0.1
            
            # 5. Find Reverb template match
            match_result = self._find_template_match(plugin_win, self.reverb_template_path, "Reverb")
            if not match_result or match_result[0] is None:
                return False
            
            result_data, confidence = match_result
            click_x, click_y = result_data['click_pos']
            
            # 6. Perform Reverb action (similar to COMP)
            print(f"üëÜ Clicking Reverb center: ({click_x}, {click_y})")
            pyautogui.click(click_x, click_y)
            time.sleep(0.05)  # Gi·∫£m t·ª´ 0.1 xu·ªëng 0.05
            
            print("‚è∞ Waiting 0.2s...")  # Gi·∫£m t·ª´ 0.5s xu·ªëng 0.2s
            time.sleep(0.2)
            
            estimated_template_height = 100
            template_top_y = click_y - (estimated_template_height // 2)
            top_click_y = template_top_y - 15
            print(f"üëÜ Double clicking above template: ({click_x}, {top_click_y})")
            pyautogui.doubleClick(click_x, top_click_y)
            time.sleep(0.1)  # Gi·∫£m t·ª´ 0.2 xu·ªëng 0.1
            
            print(f"‚å®Ô∏è Typing Reverb value: {value}")
            pyautogui.typewrite(str(value))
            time.sleep(0.05)  # Gi·∫£m t·ª´ 0.1 xu·ªëng 0.05
            
            print("‚Ü©Ô∏è Pressing Enter")
            pyautogui.press('enter')
            time.sleep(0.1)  # Gi·∫£m t·ª´ 0.2 xu·ªëng 0.1
            
            print(f"‚úÖ Reverb set to {value} successfully")
            self.current_reverb = value
            return True
            
        except Exception as e:
            print(f"‚ùå Error setting Reverb value: {e}")
            return False
        finally:
            # Restore cursor position
            pyautogui.moveTo(original_pos[0], original_pos[1])
    
    # ==================== BASS/TREBLE METHODS ====================
    
    def set_bass_value(self, value):
        """ƒê·∫∑t gi√° tr·ªã Bass (LOW)."""
        value = max(self.bass_min, min(self.bass_max, int(value)))
        
        print(f"üîâ XVox Bass (LOW) - Setting value to: {value}")
        
        # Store original cursor position
        original_pos = pyautogui.position()
        
        try:
            # 1-4. Same setup
            proc = self._find_cubase_process()
            if not proc:
                return False
                
            if not self._focus_cubase_window(proc):
                return False
            
            plugin_win = self._find_xvox_window()
            if not plugin_win:
                return False
            
            plugin_win.activate()
            time.sleep(0.1)  # Gi·∫£m t·ª´ 0.3 xu·ªëng 0.1
            
            # 4. Find tone mic template v√† OCR ƒë·ªÉ t√¨m LOW text (like original)
            result = self._find_tone_mic_template(plugin_win)
            if not result or not result.get('low_pos'):
                print("‚ùå Could not find LOW text position")
                return False
            
            low_pos = result['low_pos']
            print(f"‚úÖ Found LOW text at: {low_pos}")
            
            # 5. Click v√†o LOW text
            pyautogui.click(low_pos[0], low_pos[1])
            time.sleep(0.05)  # Gi·∫£m t·ª´ 0.2 xu·ªëng 0.05
            print(f"üñ± Clicked on LOW text at {low_pos}")
            
            # 6. Click ·ªü v·ªã tr√≠ chi·ªÅu d·ªçc 35% t·ª´ tr√™n xu·ªëng (convert to absolute coordinates)
            template_match = result['template_match']
            template_top = template_match['location'][1]  # Relative Y in plugin window
            template_height = template_match['template_size'][1]
            
            # Convert to absolute screen coordinates
            click_y = plugin_win.top + template_top + (template_height * 0.35)
            click_x = low_pos[0]
            
            pyautogui.click(click_x, click_y)
            time.sleep(0.05)  # Gi·∫£m t·ª´ 0.2 xu·ªëng 0.05
            print(f"üñ± Clicked at 35% position: ({click_x}, {click_y})")
            
            # 7. Select text and input value
            pyautogui.tripleClick(click_x, click_y)
            time.sleep(0.05)  # Gi·∫£m t·ª´ 0.1 xu·ªëng 0.05
            print("üñ± Triple-clicked to select text")
            
            pyautogui.typewrite(str(value))
            time.sleep(0.05)  # Gi·∫£m t·ª´ 0.1 xu·ªëng 0.05
            print(f"‚å®Ô∏è Typed value: {value}")
            
            pyautogui.press('enter')
            time.sleep(0.05)  # Gi·∫£m t·ª´ 0.2 xu·ªëng 0.05
            print("‚å®Ô∏è Pressed Enter to confirm")
            
            print(f"‚úÖ Successfully set Bass (LOW) to {value}")
            self.current_bass = value
            return True
            
        except Exception as e:
            print(f"‚ùå Error setting Bass value: {e}")
            return False
        finally:
            # Restore cursor position
            pyautogui.moveTo(original_pos[0], original_pos[1])
    
    def set_treble_value(self, value):
        """ƒê·∫∑t gi√° tr·ªã Treble (HIGH)."""
        value = max(self.treble_min, min(self.treble_max, int(value)))
        
        print(f"üîä XVox Treble (HIGH) - Setting value to: {value}")
        
        # Store original cursor position
        original_pos = pyautogui.position()
        
        try:
            # 1-4. Same setup
            proc = self._find_cubase_process()
            if not proc:
                return False
                
            if not self._focus_cubase_window(proc):
                return False
            
            plugin_win = self._find_xvox_window()
            if not plugin_win:
                return False
            
            plugin_win.activate()
            time.sleep(0.1)  # Gi·∫£m t·ª´ 0.3 xu·ªëng 0.1
            
            # 4. Find tone mic template v√† OCR ƒë·ªÉ t√¨m HIGH text (like original)
            result = self._find_tone_mic_template(plugin_win)
            if not result or not result.get('high_pos'):
                print("‚ùå Could not find HIGH text position")
                return False
            
            high_pos = result['high_pos']
            print(f"‚úÖ Found HIGH text at: {high_pos}")
            
            # 5. Click v√†o HIGH text
            pyautogui.click(high_pos[0], high_pos[1])
            time.sleep(0.05)  # Gi·∫£m t·ª´ 0.2 xu·ªëng 0.05
            print(f"üñ± Clicked on HIGH text at {high_pos}")
            
            # 6. Click ·ªü v·ªã tr√≠ chi·ªÅu d·ªçc 35% t·ª´ tr√™n xu·ªëng (convert to absolute coordinates)
            template_match = result['template_match']
            template_top = template_match['location'][1]  # Relative Y in plugin window
            template_height = template_match['template_size'][1]
            
            # Convert to absolute screen coordinates
            click_y = plugin_win.top + template_top + (template_height * 0.35)
            click_x = high_pos[0]
            
            pyautogui.click(click_x, click_y)
            time.sleep(0.05)  # Gi·∫£m t·ª´ 0.2 xu·ªëng 0.05
            print(f"üñ± Clicked at 35% position: ({click_x}, {click_y})")
            
            # 7. Select text and input value
            pyautogui.tripleClick(click_x, click_y)
            time.sleep(0.05)  # Gi·∫£m t·ª´ 0.1 xu·ªëng 0.05
            print("üñ± Triple-clicked to select text")
            
            pyautogui.typewrite(str(value))
            time.sleep(0.05)  # Gi·∫£m t·ª´ 0.1 xu·ªëng 0.05
            print(f"‚å®Ô∏è Typed value: {value}")
            
            pyautogui.press('enter')
            time.sleep(0.05)  # Gi·∫£m t·ª´ 0.2 xu·ªëng 0.05
            print("‚å®Ô∏è Pressed Enter to confirm")
            
            print(f"‚úÖ Successfully set Treble (HIGH) to {value}")
            self.current_treble = value
            return True
            
        except Exception as e:
            print(f"‚ùå Error setting Treble value: {e}")
            return False
        finally:
            # Restore cursor position
            pyautogui.moveTo(original_pos[0], original_pos[1])
    
    def _find_tone_mic_template(self, xvox_window):
        """T√¨m tone mic template v√† OCR v√πng ƒë√≥ ƒë·ªÉ t√¨m LOW/HIGH trong XVox plugin (c·∫£i ti·∫øn)."""
        try:
            # L·∫•y th√¥ng tin c·ª≠a s·ªï XVox
            x, y, w, h = xvox_window.left, xvox_window.top, xvox_window.width, xvox_window.height
            print(f"üìê XVox window: {x}, {y}, {w}x{h}")
            
            # Screenshot XVox window
            screenshot = pyautogui.screenshot(region=(x, y, w, h))
            screenshot_np = np.array(screenshot)
            screenshot_gray = cv2.cvtColor(screenshot_np, cv2.COLOR_RGB2GRAY)
            
            print(f"üìê XVox screenshot size: {w}x{h}")
            
            # Load template
            template = cv2.imread(self.tone_mic_template_path, cv2.IMREAD_GRAYSCALE)
            if template is None:
                print(f"‚ùå Cannot load tone mic template: {self.tone_mic_template_path}")
                return None
                
            template_h, template_w = template.shape[:2]
            print(f"üìê Tone Mic template size: {template_w}x{template_h}")
            
            # Adaptive template matching
            best_result = TemplateHelper.adaptive_template_match(screenshot_gray, template)
            
            print(f"üèÜ Tone Mic best method: {best_result['method']}")
            print(f"üîç Tone Mic confidence: {best_result['confidence']:.3f}")
            print(f"üìè Tone Mic scale: {best_result['scale']:.2f}")
            
            if best_result['confidence'] < config.TEMPLATE_MATCH_THRESHOLD:
                print(f"‚ùå Tone Mic template confidence too low: {best_result['confidence']:.3f}")
                return None
            
            # Template match coordinates
            match_x, match_y = best_result['location']
            scaled_w, scaled_h = best_result['template_size']
            
            print(f"‚úÖ Tone Mic template found at: ({match_x}, {match_y}) with size {scaled_w}x{scaled_h}")
            
            # Define OCR region (to√†n b·ªô template area)
            ocr_x, ocr_y = match_x, match_y
            ocr_w, ocr_h = scaled_w, scaled_h
            
            print(f"üìñ OCR region: ({ocr_x}, {ocr_y}, {ocr_w}x{ocr_h})")
            
            # Direct capture OCR region
            absolute_ocr_x = x + ocr_x
            absolute_ocr_y = y + ocr_y
            ocr_region_pil = pyautogui.screenshot(region=(absolute_ocr_x, absolute_ocr_y, ocr_w, ocr_h))
            
            # Convert OCR region to grayscale
            print("üìñ Converting OCR region to grayscale...")
            ocr_region_np = np.array(ocr_region_pil)
            ocr_region_gray = cv2.cvtColor(ocr_region_np, cv2.COLOR_RGB2GRAY)
            
            # Convert back to PIL for OCR
            from PIL import Image
            ocr_region_gray_pil = Image.fromarray(ocr_region_gray, mode='L')
            
            print("üìñ OCR on grayscale region...")
            ocr_data = OCRHelper.extract_text_data(ocr_region_gray_pil)
            words = OCRHelper.get_text_words(ocr_data)
            print(f"üìú OCR text in tone mic region: {words}")
            
            # T√¨m v·ªã tr√≠ LOW v√† HIGH
            low_pos = None
            high_pos = None
            low_index = -1  # L∆∞u index c·ªßa LOW ƒë·ªÉ t√¨m HIGH
            
            # B∆∞·ªõc 1: T√¨m v·ªã tr√≠ LOW
            for i, text in enumerate(ocr_data["text"]):
                if text and text.strip():
                    text_clean = text.strip().upper()
                    
                    if "LOW" in text_clean:
                        # T√≠nh v·ªã tr√≠ absolute c·ªßa LOW
                        low_x = x + ocr_x + ocr_data["left"][i] + ocr_data["width"][i] // 2
                        low_y = y + ocr_y + ocr_data["top"][i] + ocr_data["height"][i] // 2
                        low_pos = (low_x, low_y)
                        low_index = i
                        print(f"üîâ Found LOW at index {i}: ({low_x}, {low_y})")
                        break
            
            # B∆∞·ªõc 2: T√¨m v·ªã tr√≠ HIGH
            # 2a. Th·ª≠ t√¨m tr·ª±c ti·∫øp t·ª´ OCR
            for i, text in enumerate(ocr_data["text"]):
                if text and text.strip():
                    text_clean = text.strip().upper()
                    
                    if "HIGH" in text_clean:
                        # T√≠nh v·ªã tr√≠ absolute c·ªßa HIGH
                        high_x = x + ocr_x + ocr_data["left"][i] + ocr_data["width"][i] // 2
                        high_y = y + ocr_y + ocr_data["top"][i] + ocr_data["height"][i] // 2
                        high_pos = (high_x, high_y)
                        print(f"üîä Found HIGH at index {i}: ({high_x}, {high_y})")
                        break
            
            # 2b. N·∫øu kh√¥ng t√¨m th·∫•y HIGH, s·ª≠ d·ª•ng v·ªã tr√≠ c√°ch LOW hai ƒë∆°n v·ªã
            if not high_pos and low_index >= 0:
                # Theo log c·ªßa b·∫°n, HIGH c√°ch LOW 2 ƒë∆°n v·ªã trong m·∫£ng
                high_index = low_index + 2  # V·ªã tr√≠ c√°ch LOW hai ƒë∆°n v·ªã
                
                # Ki·ªÉm tra xem index c√≥ h·ª£p l·ªá kh√¥ng
                if high_index < len(ocr_data["text"]):
                    high_text = ocr_data["text"][high_index]
                    if high_text and high_text.strip():
                        # T√≠nh v·ªã tr√≠ absolute c·ªßa HIGH (d·ª±a v√†o v·ªã tr√≠ c√°ch LOW hai ƒë∆°n v·ªã)
                        high_x = x + ocr_x + ocr_data["left"][high_index] + ocr_data["width"][high_index] // 2
                        high_y = y + ocr_y + ocr_data["top"][high_index] + ocr_data["height"][high_index] // 2
                        high_pos = (high_x, high_y)
                        print(f"üîä Found HIGH at index {high_index} (text: '{high_text}'): ({high_x}, {high_y})")
                    else:
                        print(f"‚ö†Ô∏è Text at position {high_index} is empty")
                else:
                    print(f"‚ö†Ô∏è Position {high_index} is out of range")
            
            # 2c. N·∫øu v·∫´n kh√¥ng t√¨m th·∫•y, th·ª≠ ph∆∞∆°ng ph√°p d·ª±a tr√™n v·ªã tr√≠ (fallback)
            if not low_pos or not high_pos:
                print("‚ö†Ô∏è S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p d·ª±a tr√™n v·ªã tr√≠ (fallback)...")
                
                # L·ªçc ra c√°c text c√≥ content
                valid_texts = []
                for i, text in enumerate(ocr_data["text"]):
                    if text and text.strip():
                        text_info = {
                            'text': text.strip(),
                            'index': i,
                            'left': ocr_data["left"][i],
                            'top': ocr_data["top"][i],
                            'width': ocr_data["width"][i],
                            'height': ocr_data["height"][i]
                        }
                        valid_texts.append(text_info)
                
                print(f"üìù Valid OCR texts: {[t['text'] for t in valid_texts]}")
                
                # N·∫øu c√≥ √≠t nh·∫•t 3 elements
                if len(valid_texts) >= 3:
                    # Element ƒë·∫ßu ti√™n = LOW
                    if not low_pos:
                        low_info = valid_texts[0]
                        low_x = x + ocr_x + low_info['left'] + low_info['width'] // 2
                        low_y = y + ocr_y + low_info['top'] + low_info['height'] // 2
                        low_pos = (low_x, low_y)
                        print(f"üîâ Fallback LOW ('{low_info['text']}') at: ({low_x}, {low_y})")
                    
                    # Element th·ª© 3 = HIGH  
                    if not high_pos:
                        high_info = valid_texts[2]
                        high_x = x + ocr_x + high_info['left'] + high_info['width'] // 2
                        high_y = y + ocr_y + high_info['top'] + high_info['height'] // 2
                        high_pos = (high_x, high_y)
                        print(f"üîä Fallback HIGH ('{high_info['text']}') at: ({high_x}, {high_y})")
            
            # Save debug image 
            debug_filename = "tone_mic_ocr_debug.png"
            debug_path = ImageHelper.save_template_debug_image(
                screenshot_np, template, (match_x, match_y), 
                best_result['confidence'], debug_filename
            )
            print(f"üñº Tone mic OCR debug saved -> {debug_path}")
            
            return {
                'low_pos': low_pos,
                'high_pos': high_pos,
                'template_match': best_result,
                'ocr_words': words
            }
            
        except Exception as e:
            print(f"‚ùå Error in tone mic template detection: {e}")
            return None
            
    def _perform_ocr_workflow(self, plugin_win, template_match, target_text, value, control_name):
        """Th·ª±c hi·ªán OCR workflow cho Bass/Treble."""
        x, y, w, h = plugin_win.left, plugin_win.top, plugin_win.width, plugin_win.height
        screenshot = pyautogui.screenshot(region=(x, y, w, h))
        screenshot_np = np.array(screenshot)
        screenshot_gray = cv2.cvtColor(screenshot_np, cv2.COLOR_RGB2GRAY)
        
        # Convert to PIL for OCR (like the original code)
        from PIL import Image
        screenshot_pil = Image.fromarray(screenshot_gray, mode='L')
        
        # OCR to find LOW/HIGH text
        print("üìñ OCR on grayscale region...")
        ocr_data = OCRHelper.extract_text_data(screenshot_pil)
        words = OCRHelper.get_text_words(ocr_data)
        print(f"üìú OCR text in tone mic region: {words}")
        
        target_pos = None
        
        # Look for exact target text first (like original code)
        for i, text in enumerate(ocr_data["text"]):
            if text and text.strip():
                text_clean = text.strip().upper()
                
                if target_text in text_clean:
                    # Calculate absolute position (like original)
                    target_x = x + ocr_data["left"][i] + ocr_data["width"][i] // 2
                    target_y = y + ocr_data["top"][i] + ocr_data["height"][i] // 2
                    target_pos = (target_x, target_y)
                    print(f"   ‚úÖ Found {target_text} text at position {i}: {target_pos}")
                    break
        
        # Fallback: use position-based detection (like original)
        if not target_pos and len(ocr_data["text"]) >= 3:
            if target_text == "LOW":
                i = 0  # First element
            else:  # HIGH
                i = 2  # Third element
            
            if i < len(ocr_data["text"]):
                target_x = x + ocr_data["left"][i] + ocr_data["width"][i] // 2
                target_y = y + ocr_data["top"][i] + ocr_data["height"][i] // 2
                target_pos = (target_x, target_y)
                print(f"   üîÑ Using fallback position for {target_text}: {target_pos}")
        
        if not target_pos:
            print(f"‚ùå Could not find {target_text} position")
            return False
        
        # Calculate click position (40% down from template top)
        template_top = template_match['location'][1]
        template_height = template_match['template_size'][1]
        
        click_y = template_top + (template_height * 0.40)
        click_x = target_pos[0]
        
        pyautogui.click(click_x, click_y)
        time.sleep(0.05)  # Gi·∫£m t·ª´ 0.2 xu·ªëng 0.05
        print(f"üñ± Clicked at 40% position: ({click_x}, {click_y})")
        
        # Select text and input value
        pyautogui.tripleClick(click_x, click_y)
        time.sleep(0.05)  # Gi·∫£m t·ª´ 0.1 xu·ªëng 0.05
        print("üñ± Triple-clicked to select text")
        
        pyautogui.hotkey('ctrl', 'a')
        time.sleep(0.05)  # Gi·∫£m t·ª´ 0.1 xu·ªëng 0.05
        print("‚å®Ô∏è Also tried Ctrl+A")
        
        pyautogui.typewrite(str(value))
        time.sleep(0.05)  # Gi·∫£m t·ª´ 0.1 xu·ªëng 0.05
        print(f"‚å®Ô∏è Typed value: {value}")
        
        pyautogui.press('enter')
        time.sleep(0.05)  # Gi·∫£m t·ª´ 0.2 xu·ªëng 0.05
        print("‚å®Ô∏è Pressed Enter to confirm")
        
        print(f"‚úÖ Successfully set {control_name} ({target_text}) to {value}")
        
        if target_text == "LOW":
            self.current_bass = value
        else:
            self.current_treble = value
            
        return True
    
    def execute(self):
        """Execute XVox detection."""
        return self._find_xvox_window() is not None